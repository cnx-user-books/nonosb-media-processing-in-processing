<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML">
  <title>Textures in Processing</title>
  <metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m13048</md:content-id>
  <md:title>Textures in Processing</md:title>
  <md:abstract>A brief guide to texture mapping in Processing</md:abstract>
  <md:uuid>5edd53ae-0e64-415b-b0fd-ec81ac9b7c65</md:uuid>
</metadata>
  <content>
    <section id="color_interpolation">
      <title>Color Interpolation </title>
      <para id="color_interpolationp">
	As seen in <link document="m12665">Graphic Composition in
	Processing</link>, one can obtain surfaces as
	collections of polygons by means of the  definition of a vertex
	within the couple <code>beginShape()</code> -
	<code>endShape()</code>. It is possible to assign a color to one or more vertices, in order to make the color variations continuous (<term>gradient</term>). For example, you can try to run the code 
	<code id="id1170227075452" display="block"> 
	  size(200,200,P3D);
          beginShape(TRIANGLE_STRIP);
          fill(240,   0, 0); vertex(20,31, 33);
          fill(240, 150, 0); vertex(80, 40, 38);
          fill(250, 250, 0); vertex(75, 88, 50);
                             vertex(49, 85, 74);
          endShape();</code>
	in order to obtain a continuous nuance from red to yellow in the strip of two triangles.
      </para>
      <section id="bilinear">
	<title>Bilinear Interpolation </title>
      <para id="bilinearp">
	The graphical system performs an interpolation of color values assigned
to the vertices. This type of  <term>bilinear interpolation
	</term> is defined in the following way:
	<list id="bilinearlist">
	  <item>For each polygon of the collection</item>
	  <item><list id="bilinearlist1"><item>For each side of the polygon one assigns to each point on the  segment the color obtained by means of linear interpolation of the colors of the vertices <m:math>
		  <m:ci>i</m:ci>
		</m:math> e <m:math>
		  <m:ci>j</m:ci>
		</m:math> that define the polygon:
		  <m:math>
		  <m:apply>
		    <m:eq/>
		    <m:apply>
		    <m:ci type="fn">
		    <m:msub>
		      <m:mi>C</m:mi>
		      <m:mn>ij</m:mn>
		    </m:msub>
		    </m:ci>
		    <m:ci>α</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:plus/>
		     <m:apply>
		      <m:times/>
<!--		      <m:apply>
			<m:minus/> -->
			<m:cn>(1</m:cn>
                        <m:mo>-</m:mo>
			<m:ci>α)</m:ci>
<!--		      </m:apply> -->
		      <m:msub>
			<m:mi>C</m:mi>
			<m:mn>i</m:mn>
		      </m:msub>
		     </m:apply>
		    <m:apply>
		      <m:times/>
		      <m:ci>α</m:ci>
		      <m:msub>
			<m:mi>C</m:mi>
			<m:mn>j</m:mn>
		      </m:msub>
		    </m:apply>
		    </m:apply>
		  </m:apply>
		</m:math>
	      </item>
	    </list>
	  </item>
	  <item>
	    <list id="bilinearlist2"><item>A <term>scan line</term> scans the polygon (or, better, its projection on the image window) intersecting at each step two sides in two points <m:math>
		    <m:ci>l</m:ci>
		  </m:math> ed <m:math>
		    <m:ci>r</m:ci>
		  </m:math>
whose colors have already been identified as <m:math>
		  <m:msub>
		    <m:mi>C</m:mi>
		    <m:mn>l</m:mn>
		  </m:msub>
		</m:math> e <m:math>
		  <m:msub>
		    <m:mi>C</m:mi>
		    <m:mn>r</m:mn>
		  </m:msub>
		</m:math>. In each point of the scan line the color is determined by linear interpolation  <m:math>
		  <m:apply>
		    <m:eq/>
		    <m:apply>
		    <m:ci type="fn">
		    <m:msub>
		      <m:mi>C</m:mi>
		      <m:mn>lr</m:mn>
		    </m:msub>
		    </m:ci>
		      <m:ci>β</m:ci>
		    </m:apply>
		    <m:apply>
		      <m:plus/>
		     <m:apply>
		      <m:times/>
<!--		      <m:apply>
			<m:minus/> -->
			<m:cn>(1</m:cn>
                        <m:mo>-</m:mo>
			<m:ci>β)</m:ci>
<!-- 		      </m:apply> -->
		      <m:msub>
			<m:mi>C</m:mi>
			<m:mn>l</m:mn>
		      </m:msub>
		     </m:apply>
		    <m:apply>
		      <m:times/>
		      <m:ci>β</m:ci>
		      <m:msub>
			<m:mi>C</m:mi>
			<m:mn>r</m:mn>
		      </m:msub>
		    </m:apply>
		    </m:apply>
		  </m:apply>
		</m:math>
</item>
	    </list>
	  </item>
	</list>
      </para>
      <para id="colorint_examplep">A significative example of interpolation of colors associated
to the vertices of a cube can be found in <link url="http://processing.org/learning/3d/">examples of
	  Processing</link>, in the code <link url="http://processing.org/learning/3d/rgbcube.html">
	  RGB Cube</link>.
      </para>
    </section>
    </section>
    <section id="texture">
      <title>Texture</title>
      <para id="texture1p">
	When modeling a complex scene by means of a composition of
	simple graphical elements one cannot go beyond a certain
	threshold of complexity. Let us think about the example of a
	modelization of a natural scene, where one has to represent
	each single vegetal element, including the grass of a
	meadow. It is unconceivable to do this manually. It would be
	possible to set and control the grass elements by means of
	some algorithms. This is an approach taken, for example, in
	rendering the hair and skin of characters of the most
	sophisticated animation movies (see for example, <link url="http://www.computerarts.co.uk/in_depth/features/inside_the_incredibles">the
	Incredibles</link>). Otherwise, especially in case of
	interactive graphics, one has to resort to using
	<term>textures</term>. In other words, one employs images that
	represent the visual texture of the surfaces and map them on
	the polygons that model the objects of the scene. In order to
	have a qualitative rendering of the surfaces it is necessary
	to limit the detail level to fragments not smaller than one
	pixel and, thus, the <term>texture mapping</term> is inserted
	in the rendering chain at the <term>rastering</term> level of
	the graphic primitives, i.e. where one passes from a 3D
	geometric description to the illumination of the pixels on the
	display. It is at this level that the removal of the
	hidden surfaces takes place, since we are interested only in
	the visible fragments. </para>
      <para id="texturep">
	In Processing, a texture is defined within a block
	<code>beginShape()</code> - <code>endShape()</code> by means
	of the function <code>texture()</code> that has as unique
	parameter a variable of type <code>PImage</code>. The
	following calls to <code>vertex()</code> can contain, as last
	couple of parameters, the point of the texture corresponding
	to the vertex.  In fact, each texture image is parameterized
	by means of two variables <m:math> <m:ci>u</m:ci> </m:math>
	and <m:math> <m:ci>v</m:ci> </m:math>, that can be referred
	directly to the line and column of a <term>texel</term> (pixel
	of a texture) or, alternatively, normalized between <m:math>
	<m:mn>0</m:mn> </m:math> and <m:math> <m:mn>1</m:mn>
	</m:math>, in such a way that one can ignore the dimension as
	well as the width and height of the texture itself. The
	meaning of the parameters <m:math> <m:ci>u</m:ci> </m:math>
	and <m:math> <m:ci>v</m:ci> </m:math> is established by the
	command <code>textureMode()</code> with parameter
	<code>IMAGE</code> or <code>NORMALIZED</code>.
      </para>
      <example id="chimeraex">
	<para id="chimeraexp">
	  In the code that follows the image <link resource=".">
		      representing a broken glass </link> is employed
		      as texture and followed by a color interpolation
		      and the default illumination. The
		      <term>shading</term> of the surfaces, produced
		      by means of the illumination and the colors, is
		      modulated in a multiplicative way by the colors
		      of the texture.
	  <code id="id1271618" display="block">
            size(400,400,P3D);
            PImage a = loadImage("vetro.jpg");
            lights();
            textureMode(NORMALIZED);
            beginShape(TRIANGLE_STRIP);
            texture(a);
            fill(240,   0, 0); vertex(40,61, 63, 0, 0);
            fill(240, 150, 0); vertex(340, 80, 76, 0, 1);
            fill(250, 250, 0); vertex(150, 176, 100, 1, 1);
                               vertex(110, 170, 180, 1, 0);
            endShape();
	  </code>
	</para>
      </example>
    </section>
    <section id="texture_mapping">
      <title>Texture mapping</title>
      <para id="texture_mappingp">
	It is evident that the mapping operations from a texture image
	  to an object surface, of arbitrary shape, implies some form
	  of interpolation. Similarly to what happens for colors, only
	  the vertices that delimit the surface are mapped onto exact
	  points of the texture image. What happens for the internal
	  points has to be established in some way. Actually,
	  Processing and OpenGL behave according to what illustrated
	  in <link target-id="bilinear"/>, i.e. by bilinear
	  interpolation: a first linear interpolation over each
	  boundary segment is cascaded by a linear interpolation on a
	  scan line. If <m:math> <m:ci>u</m:ci> </m:math> and <m:math>
	  <m:ci>v</m:ci> </m:math> exceed the limits of the texture
	  image, the system (Processing) can assume that this is
	  repeated periodically and fix it to the values at the
	  border.
      </para>
      <para id="aliasingp">
	A problem that occurs is that a pixel on a display does not
	necessarly correspond exactly to a texel. One can map more
	than one texel on a pixel or, viceversa, a texel can be mapped
	on several pixels. The first case corresponds to a
	downsampling that, as seen in <link document="m12751">Sampling
	and Quantization</link>, can produce aliasing. The effect of
	aliasing can be attenuated by means of low pass filtering of
	the texture image. The second case corresponds to
	upsampling, that in the frequency domain can be interpreted as
	increasing the distance between spectral images.
      </para>
    </section>
    <section id="texturegen">
      <title>Texture Generation</title>
      <para id="texturegenp">
      Textures are not necessarely imported from images, but they can
      also be generated in an algorithmic fashion. This is
      particularly recommended when one wants to generate regular or
      pseudo-random patterns. For example, the pattern of a
      chess-board can be generated by means of the code

<code id="id7678001" display="block">  PImage textureImg =
loadImage("vetro.jpg"); // dummy image colorMode(RGB,1);

int biro = 0;
int bbiro = 0;
int scacco = 5;
for (int i=0; i&lt;textureImg.width; i+=scacco) {
   bbiro = (bbiro + 1)%2; biro = bbiro;
   for (int j=0; j&lt;textureImg.height; j+=scacco) {
     for (int r=0; r&lt;scacco; r++)
       for (int s=0; s&lt;scacco; s++)
        textureImg.set(i+r,j+s, color(biro));
    biro = (biro + 1)%2; 
  }
}
image(textureImg, 0, 0);

      </code>
      </para>
      <para id="randomfilterp">
	The use of the function random, combined with filters of
	various type, allows a wide flexibility in the production of
	textures. For example, the pattern represented in <link target-id="expattern"/> was obtained from a modification of the
	code generating the chess-board. In particular, we added the
	line <code>scacco=floor(2+random(5));</code> within the outer
	<code>for</code>, and applied an averaging filter.
      <figure id="expattern">
	<title>Algorithmically-generated pattern</title>
 	<media id="id1170227136270" alt=""><image src="../../media/expattern.png" mime-type="image/png"/></media>
     </figure>
      </para>
    </section>
    <exercise id="ingrandimentop">
      <problem id="id1170225884972">
	<para id="ingrandimentopp">
	  How could one modify the code <link target-id="chimeraex"/> in
	  order to make the breaks in the glass more evident?
	</para>
      </problem>
      <solution id="id1170226934774">
	<para id="ingrandimentops">
	  It is sufficient to consider only a piece of the texture,
	  with calls of the type <code>vertex(150, 176, 0.3,
	  0.3);</code>
	</para>
      </solution>
    </exercise>
    <exercise id="patternrico">
      <problem id="id1170234022145">
	<para id="patternricop">
	  The excercise consists in modifying the code of the
	  generator of the chess-board in <link target-id="texturegen"/>
	  in order to generate the texture <link target-id="expattern"/>.
	</para>
      </problem>
    </exercise>
    <exercise id="checker">
      <problem id="id7023353">
	<para id="checkerp">
	  This exercise consists in running and analyzing the
          following code. Try then to vary the dimensions of the small
          squares and the filtering type.  <code id="id4914744" display="block">
          

size(200, 100, P3D);

PImage textureImg = loadImage("vetro.jpg"); // dummy image
colorMode(RGB,1);

int biro = 0;
int bbiro = 0;
int scacco = 5;
for (int i=0; i&lt;textureImg.width; i+=scacco) {
   // scacco=floor(2+random(5));
   bbiro = (bbiro + 1)%2; biro = bbiro;
   for (int j=0; j&lt;textureImg.height; j+=scacco) {
     for (int r=0; r&lt;scacco; r++)
       for (int s=0; s&lt;scacco; s++)
        textureImg.set(i+r,j+s, color(biro));
    biro = (biro + 1)%2; 
  }
}
image(textureImg, 0, 0);
textureMode(NORMALIZED);
beginShape(QUADS);
  texture(textureImg);
  vertex(20, 20, 0, 0);
  vertex(80, 25, 0, 0.5);
  vertex(90, 90, 0.5, 0.5);
  vertex(20, 80, 0.5, 0);
endShape();

// ------ filtering -------

PImage tImg = loadImage("vetro.jpg"); // dummy image
float val = 1.0/9.0;
float[][] kernel = { {val, val, val}, 
                     {val, val, val}, 
                     {val, val, val} }; 
int n2 = 1; 
int m2 = 1;
colorMode(RGB,255);
// Convolve the image 
for(int y=0; y&lt;textureImg.height; y++) { 
  for(int x=0; x&lt;textureImg.width/2; x++) { 
    float sum = 0; 
    for(int k=-n2; k&lt;=n2; k++) { 
      for(int j=-m2; j&lt;=m2; j++) { 
        // Reflect x-j to not exceed array boundary 
        int xp = x-j; 
        int yp = y-k; 
        if (xp &lt; 0) { 
          xp = xp + textureImg.width; 
        } else if (x-j &gt;= textureImg.width) { 
          xp = xp - textureImg.width; 
        } 
        // Reflect y-k to not exceed array boundary 
        if (yp &lt; 0) { 
          yp = yp + textureImg.height; 
        } else if (yp &gt;= textureImg.height) { 
          yp = yp - textureImg.height; 
        } 
        sum = sum + kernel[j+m2][k+n2] * red(textureImg.get(xp, yp)); 
      } 
    } 
    tImg.set(x,y, color(int(sum)));
  } 
} 
 
translate(100, 0);
beginShape(QUADS);
  texture(tImg);
  vertex(20, 20, 0, 0);
  vertex(80, 25, 0, 0.5);
  vertex(90, 90, 0.5, 0.5);
  vertex(20, 80, 0.5, 0);
endShape();

	  </code>
	</para>
      </problem>
    </exercise>
  </content>
  
</document>