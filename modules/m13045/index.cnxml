<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:bib="http://bibtexml.sf.net/">
  <title>Signal Processing in Processing: Sampling and Quantization</title>
  <metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m13045</md:content-id>
  <md:title>Signal Processing in Processing: Sampling and Quantization</md:title>
  <md:abstract>Fundamentals of sampling, reconstruction, and quantization of 1D (sounds) and 2D (images) signals, especially oriented at the Processing language.</md:abstract>
  <md:uuid>999eb52b-c4e4-4584-a45a-1d55e82dba3d</md:uuid>
</metadata>

  <content>
    <section id="campionamento">
      <title>Sampling</title>
      <para id="intro_campionamento">
	Both sounds and images can be considered as signals, in one or
	two dimensions, respectively. Sound can be described as a
	fluctuation of the acoustic pressure in time, while images are
	spatial distributions of values of luminance or color, the
	latter being described in its RGB or HSB components.  Any
	signal, in order to be processed by numerical computing
	devices, have to be reduced to a sequence of discrete
	<emphasis>samples</emphasis>, and each sample must be
	represented using a finite number of bits. The first operation
	is called <term>sampling</term>, and the second operation is
	called <term>quantization</term> of the domain of real
	numbers.
      </para>
      <section id="campionamento1D">
	<title>1-D: Sounds</title>
	<para id="campionamento1Dp">
	  Sampling is, for one-dimensional signals, the operation that
	  transforms a continuous-time signal (such as, for instance,
	  the air pressure fluctuation at the entrance of the ear
	  canal) into a discrete-time signal, that is a sequence of
	  numbers. The discrete-time signal gives the values of the
	  continuous-time signal read at intervals of <m:math>
	  <m:ci>T</m:ci> </m:math> seconds. The reciprocal of the
	  sampling interval is called <term>sampling rate</term>
	  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>s</m:mn>
		</m:msub>
	      </m:ci>
	    <m:apply>
	      <m:divide/>
	      <m:cn>1</m:cn>
	      <m:ci>T</m:ci>
	    </m:apply>
	    </m:apply>
	  </m:math>. In this module we do not explain the theory of
	  sampling, but we rather describe its manifestations. For a a
	  more extensive yet accessible treatment, we point to the
	  <cite target-id="rocISP"><cite-title>Introduction to Sound Processing</cite-title></cite>.
	  For our purposes, the process of sampling a 1-D signal can
	  be reduced to three facts and a theorem.
	</para>
	<list id="fatti">
	  <item><label>Fact 1</label> The <link document="m0046">Fourier
	      Transform</link> of a discrete-time signal is a function
	      (called <term>spectrum</term>) of the continuous
	      variable <m:math> <m:ci>ω</m:ci> </m:math>, and it
	      is periodic with period
	      <m:math>
	      <m:apply>
		<m:times/>
		<m:cn>2</m:cn>
		<m:ci>π</m:ci>
	      </m:apply>
 	      </m:math>. Given a value of <m:math><m:ci>ω</m:ci>
	      </m:math>, the Fourier transform gives back a complex
	      number that can be interpreted as magnitude and phase
	      (translation in time) of the sinusoidal component at
	      that frequency.
	  </item>
	  <item><label>Fact 2</label> Sampling the continuous-time signal <m:math>
	      <m:apply>
		<m:ci type="fn">x</m:ci>
		<m:ci>t</m:ci>
	      </m:apply>
	    </m:math>
	    with interval <m:math>
	      <m:ci>T</m:ci> 
	    </m:math> we get the discrete-time signal <m:math>
	      <m:apply>
		<m:eq/>
	      <m:apply>
		<m:ci type="fn">x</m:ci>
		<m:ci>n</m:ci>
	      </m:apply>
	      <m:apply>
		<m:ci type="fn">x</m:ci>
		  <m:apply>
		    <m:times/>
		    <m:ci>n</m:ci>
		    <m:ci>T</m:ci>
		  </m:apply>
	      </m:apply>		
	      </m:apply>
	    </m:math>, which is a function of the discrete variable <m:math>
	      <m:ci>n</m:ci>
	    </m:math>.
	  </item>
	  <item><label>Fact 3</label> Sampling a continuous-time signal
	  with sampling rate <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>s</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> produces a discrete-time signal whose frequency
	    spectrum is the periodic replication of the original
	    signal, and the replication period is <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>s</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math>. The Fourier variable <m:math>
	    <m:ci>ω</m:ci> </m:math> for functions of discrete
	    variable is converted into the frequency variable <m:math>
	    <m:ci>f</m:ci> </m:math> (in Hertz) by means of <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci>f</m:ci>
		<m:apply>
		  <m:divide/>
		  <m:ci>ω</m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>π</m:ci>
		    <m:ci>T</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>.
	  </item>
	</list>
	<para id="spettro_esp">
	  The <link target-id="repeti"/> shows an example of frequency
	  spectrum of a signal sampled with sampling rate <m:math>
	  <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>s</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math>. In the example, the continuous-time signal had
	    all and only the frequency components between <m:math>
	    <m:apply>
	      <m:minus/>
	      <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>b</m:mn>
		</m:msub>
	      </m:ci> </m:apply> </m:math> and <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>b</m:mn>
		</m:msub>
	      </m:ci>
	  </m:math>. The replicas of the original spectrum are
	  sometimes called <emphasis>images</emphasis>.
	</para>
	<figure id="repeti">
	  <title>Frequency spectrum of a sampled signal</title>
	  <media id="id1169535971601" alt=""><image src="../../media/repeti.png" mime-type="image/png"/></media>
	</figure>
	<para id="teorema_campp">
	  Given the <link target-id="fatti">facts</link>, we can have an
	  intuitive understanding of the Sampling Theorem,
	  historically attributed to the scientists Nyquist and
	  Shannon.
	</para>
	<rule id="teorema_campionamento" type="theorem">
	  <title>Sampling Theorem</title>
	  <statement id="id2267632">
	    <para id="campiona_statement">
	    A continuous-time signal <m:math>
	      <m:apply>
		<m:ci type="fn">x</m:ci>
		<m:ci>t</m:ci>
	      </m:apply>
	    </m:math>, whose spectral content is limited to
	    frequencies smaller than <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>b</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> (i.e., it is band-limited to <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>b</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math>) can be recovered from its sampled version
		<m:math> <m:apply> <m:ci type="fn">x</m:ci>
		<m:ci>n</m:ci>
	      </m:apply>
	    </m:math> if the sampling rate is larger than twice the
	    bandwidth (i.e., if <m:math>
		<m:apply>
		  <m:gt/>
		  <m:ci>
		    <m:msub>
		      <m:mi>F</m:mi>
		      <m:mn>s</m:mn>
		    </m:msub>
		  </m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		  <m:ci>
		    <m:msub>
		      <m:mi>F</m:mi>
		      <m:mn>b</m:mn>
		    </m:msub>
		  </m:ci>
		  </m:apply>
		</m:apply>
	      </m:math>)
	    </para>
	  </statement>
	</rule>
	<para id="camp_rico">The reconstruction can only occur by means of a filter that
	  cancels out all spectral images except for the one directly
	  coming from the original continuous-time signal. In other
	  words, the canceled images are those having frequency
	  components higher than the <term>Nyquist frequency</term>
	  defined as <m:math>
	    <m:apply>
	      <m:divide/>
	      <m:ci><m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>s</m:mn>
		</m:msub>
	      </m:ci>
	      <m:cn>2</m:cn>
	    </m:apply>
	  </m:math>. The condition required by the <link target-id="teorema_campionamento">sampling theorem</link> is equivalent
to saying that no overlaps between spectral images are allowed. If
such superimpositions were present, it wouldn't be possible to design
a filter that eliminates the copies of the original spectrum. In case of overlapping, a filter
that eliminates all frequency components higher than the Nyquist
frequency would produce a signal that is affected by
<term>aliasing</term>. The concept of aliasing is well illustrated in
the <link document="m11448"> Aliasing Applet</link>, where a
continuous-time sinusoid is subject to sampling. If the frequency of
the sinusoid is too high as compared to the sampling rate, we see that
the the waveform that is reconstructed from samples is not the
original sinusoid, as it has a much lower frequency. We all have
familiarity with aliasing as it shows up in moving images, for
instance when the wagon wheels in western movies start spinning
backward. In that case, the sampling rate is given by the <term>frame
rate</term>, or number of pictures per second, and has to be related
with the spinning velocity of the wheels. This is one of several <link url="http://www.michaelbach.de/ot/mot_strob/">
stroboscopic </link> phenomena.
	</para>



<para id="applet_aliasing">In the case of sound, in order to become aware of the consequences of the 
<m:math>
	      <m:apply>
		<m:times/>
		<m:cn>2</m:cn>
		<m:ci>π</m:ci>
	      </m:apply>
 	      </m:math> periodicity of discrete-time signal spectra
(see <link target-id="repeti"/>) and of violations of the condition of
the sampling theorem, we examine a simple case.

Let us consider a sound that is generated by a sum of sinusoids that
are harmonics (i.e., integer multiples) of a fundamental. The spectrum
of such sound would display peaks corresponding to the fundamental
frequency and to its integer multiples.
Just to give a concrete example, imagine working at the sampling rate of 
	  <m:math>
	    <m:cn>44100</m:cn> </m:math> Hz and summing <m:math>
<m:cn>10</m:cn> </m:math> sinusoids. From the sampling theorem we know
that, in our case, we can represent without aliasing all frequency
components up to <m:math> <m:cn>22050</m:cn> </m:math> Hz. So, in
order to avoid aliasing, the fundamental frequency should be lower
than <m:math> <m:cn>2205</m:cn> </m:math> Hz. The Processing (with Beads library)
code reported in table <link target-id="aliasingTab"/> implements a
generator of sounds formed by <m:math> <m:cn>10</m:cn> </m:math>
harmonic sinusoids. To produce such sounds it is necessary to click on
a point of the display window. The x coordinate would vary with the
fundamental frequency, and the window will show the spectral peaks
corresponding to the generated harmonics. When we click on a point
whose x coordinate is larger than <m:math>
	    <m:apply>
	      <m:divide/>
	      <m:cn>1</m:cn>
	      <m:cn>10</m:cn>
	    </m:apply>
	  </m:math> of the window width, we still see ten spectral
	  peaks. Otherwise, we violate the sampling theorem and
	  aliasing will enter our representation.
</para>


<table id="aliasingTab" frame="all" summary="Applet to demonstrate the effect of aliasing on harmonic sounds">
<tgroup cols="2" align="left" colsep="1" rowsep="1"><colspec colname="col1" colnum="1" colwidth="60"/> 
		<colspec colname="col2" colnum="2" colwidth="340"/>
		<tbody>
		  <row>
		    <entry>
		      <link resource="./index.html"> Aliasing test:
		    Applet to experience the effect of aliasing on
		    sounds obtained by summation of 10 sinusoids in
		    harmonic ratio </link> </entry>
		    <entry>
	    <code id="id1169524285218" display="block">import beads.*; // import the beads library
import beads.Buffer;
import beads.BufferFactory;

AudioContext ac; 
PowerSpectrum ps;

WavePlayer wavetableSynthesizer;
Glide frequencyGlide;
Envelope gainEnvelope;
Gain synthGain;

int L = 16384; // buffer size
int H = 10; //number of harmonics
float freq = 10.00; // fundamental frequency [Hz]
Buffer dSB;

void setup() {
  size(1024,200);

  frameRate(20);

  ac = new AudioContext();  // initialize AudioContext and create buffer
 
  frequencyGlide = new Glide(ac, 200, 10); // initial freq, and transition time
  dSB = new DiscreteSummationBuffer().generateBuffer(L, H, 0.5);
  wavetableSynthesizer = new WavePlayer(ac, frequencyGlide, dSB);
  
  gainEnvelope = new Envelope(ac, 0.0); // standard gain control of AudioContext
  synthGain = new Gain(ac, 1, gainEnvelope); 
  synthGain.addInput(wavetableSynthesizer); 
  ac.out.addInput(synthGain);
   
  // Short-Time Fourier Analysis
  ShortFrameSegmenter sfs = new ShortFrameSegmenter(ac);
  sfs.addInput(ac.out);
  FFT fft = new FFT();
  sfs.addListener(fft);
  ps = new PowerSpectrum();
  fft.addListener(ps);
  ac.out.addDependent(sfs);

  ac.start(); // start audio processing
  gainEnvelope.addSegment(0.8, 50); // attack envelope
}

void mouseReleased(){
  println("mouseX = " + mouseX);
}

void draw()
{
  background(0); 
  
  text("click and move the pointer", 800, 20); 
  frequencyGlide.setValue(float(mouseX)/width*22050/10); // set the fundamental frequency
                                                         // the 10 factor is empirically found
  float[] features = ps.getFeatures(); // from Beads analysis library  
  // It will contain the PowerSpectrum: 
  // array with the power of 256 spectral bands.
  if (features != null) { // if any features are returned
    for (int x = 0; x &lt; width; x++){
      int featureIndex = (x * features.length) / width;
      int barHeight = Math.min((int)(features[featureIndex] * 0.05 *
        height), height - 1);
      stroke(255);
      line(x, height, x, height - barHeight);
    }
  }
}

public class DiscreteSummationBuffer extends BufferFactory {
  public Buffer generateBuffer(int bufferSize) { //Beads generic buffer
    return generateBuffer(bufferSize, 10, 0.9f); //default values
  }
  public Buffer generateBuffer(int bufferSize, int numberOfHarmonics, float amplitude)
  {
    Buffer b = new Buffer(bufferSize);

    double amplitudeCoefficient = amplitude / (2.0 * (double)numberOfHarmonics);
    double theta = 0.0;
    for (int k = 0; k &lt;= numberOfHarmonics; k++) { //additive synthesis
      for (int i = 0; i &lt; b.buf.length; i++) {
        b.buf[i] = b.buf[i] + (float)Math.sin(i*2*Math.PI*freq*k/b.buf.length)/20;
      }
    }
    return b;
  }
  public String getName() { //mandatory method implementation
    return "DiscreteSummation";
  }
}
 </code>
		    </entry>
		  </row>
		</tbody>
	      

</tgroup>
</table>


      </section>

      <section id="campionaimmagini">
	<title>2-D: Images</title>
	<para id="campionamento2Dp">
	  Let us assume we have a continuous distribution, on a plane,
	    of values of luminance or, more simply stated, an
	    image. In order to process it using a computer we have to
	    reduce it to a sequence of numbers by means of
	    sampling. There are several ways to sample an image, or
	    read its values of luminance at discrete points. The
	    simplest way is to use a regular grid, with spatial steps
	    <m:math> <m:ci>X</m:ci> </m:math> e <m:math>
	    <m:ci>Y</m:ci> </m:math>. Similarly to what we did for
	    sounds, we define the spatial sampling rates <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>X</m:mn>
		</m:msub>
	      </m:ci>
	    <m:apply>
	      <m:divide/>
	      <m:cn>1</m:cn>
	      <m:ci>X</m:ci>
	    </m:apply>
	    </m:apply>
	  </m:math> and  <m:math>
	    <m:apply>
	      <m:eq/>
	      <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci>
	    <m:apply>
	      <m:divide/>
	      <m:cn>1</m:cn>
	      <m:ci>Y</m:ci>
	    </m:apply>
	    </m:apply>
	  </m:math>.  As in the one-dimensional case, also for
	  two-dimensional signals, or images, sampling can be
	  described by three facts and a theorem.
	</para>
	<list id="fatti2D">
	  <item><label>Fact 1</label> The Fourier Transform of a
	      discrete-space signal is a function (called
	      <term>spectrum</term>) of two continuous variables
	      <m:math> <m:ci> <m:msub> <m:mi>ω</m:mi>
	      <m:mn>X</m:mn>
		</m:msub>
	      </m:ci> </m:math> and <m:math>
	      <m:ci>		<m:msub>
		  <m:mi>ω</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci> </m:math>, and it is periodic in two dimensions with periods
	      <m:math>
	      <m:apply>
		<m:times/>
		<m:cn>2</m:cn>
		<m:ci>π</m:ci>
	      </m:apply>
 	      </m:math>. Given a couple of values <m:math>
	      <m:ci>		<m:msub>
		  <m:mi>ω</m:mi>
		  <m:mn>X</m:mn>
		</m:msub>
	      </m:ci> </m:math> and <m:math>
	      <m:ci>		<m:msub>
		  <m:mi>ω</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci> </m:math>, the Fourier transform gives back a
	      complex number that can be interpreted as magnitude and
	      phase (translation in space) of the sinusoidal component
	      at such spatial frequencies.
	  </item>
	  <item><label>Fact 2</label> Sampling the continuous-space signal <m:math>
	      <m:apply>
		<m:ci type="fn">s</m:ci>
		<m:ci>x</m:ci>
		<m:ci>y</m:ci>
	      </m:apply>
	    </m:math>
	    with the regular grid of steps <m:math>
	      <m:ci>X</m:ci> 
	    </m:math>, <m:math>
	      <m:ci>Y</m:ci> 
	    </m:math>, gives a discrete-space signal <m:math>
	      <m:apply>
		<m:eq/>
	      <m:apply>
		<m:ci type="fn">s</m:ci>
		<m:ci>m</m:ci>
		<m:ci>n</m:ci>
	      </m:apply>
	      <m:apply>
		<m:ci type="fn">s</m:ci>
		  <m:apply>
		    <m:times/>
		    <m:ci>m</m:ci>
		    <m:ci>X</m:ci>
		  </m:apply>
		  <m:apply>
		    <m:times/>
		    <m:ci>n</m:ci>
		    <m:ci>Y</m:ci>
		  </m:apply>
	      </m:apply>		
	      </m:apply>
	    </m:math>, which is a function of the discrete variables <m:math>
	      <m:ci>m</m:ci>
	    </m:math> and <m:math>
	      <m:ci>n</m:ci>
	    </m:math>.
	  </item>
	  <item><label>Fact 3</label> Sampling a continuous-space signal
	  with spatial frequencies <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>X</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> and <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> gives a discrete-space signal whose spectrum is
	    the periodic replication along the grid of steps <m:math>
	    <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>X</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> and <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> of the original signal spectrum. The Fourier variables
	    <m:math>
	      <m:ci> <m:msub> <m:mi>ω</m:mi> <m:mn>X</m:mn>
		</m:msub>
	      </m:ci> </m:math> and <m:math>
	      <m:ci>		<m:msub>
		  <m:mi>ω</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci> </m:math> correspond to the frequencies (in
	      cycles per meter) represented by the variables <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci><m:msub>
		    <m:mi>f</m:mi>
		    <m:mn>X</m:mn>
		  </m:msub> </m:ci>
		<m:apply>
		  <m:divide/>
		  <m:ci><m:msub>
		  <m:mi>ω</m:mi>
		  <m:mn>X</m:mn>
		</m:msub></m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>π</m:ci>
		    <m:ci>X</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math> and <m:math>
	      <m:apply>
		<m:eq/>
		<m:ci><m:msub>
		    <m:mi>f</m:mi>
		    <m:mn>Y</m:mn>
		  </m:msub> </m:ci>
		<m:apply>
		  <m:divide/>
		  <m:ci><m:msub>
		  <m:mi>ω</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub></m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		    <m:ci>π</m:ci>
		    <m:ci>Y</m:ci>
		  </m:apply>
		</m:apply>
	      </m:apply>
	    </m:math>.
	  </item>
	</list>
	<para id="spettro_es2Dp">
	  The <link target-id="repeti2D"/> shows an example of spectrum
	  of a two-dimensional sampled signal. There, the
	  continuous-space signal had all and only the frequency
	  components included in the central hexagon.  The hexagonal
	  shape of the spectral support (region of non-null spectral
	  energy) is merely illustrative. The replicas of the original
	  spectrum are often called spectral
	  <emphasis>images</emphasis>.
	</para>
      <figure id="repeti2D">
	  <title>Spectrum of a sampled image</title>
	  <media id="id1169532688969" alt=""><image src="../../media/repeti2D.png" mime-type="image/png"/></media>
	</figure>
	<para id="teorema_campp2D">
	  Given the above <link target-id="fatti2D">facts</link>, we can
	  have an intuitive understanding of the Sampling Theorem.
	</para>
	<rule id="teorema_campionamento2D" type="theorem">
	  <title>Sampling Theorem (in 2D)</title>
	  <statement id="id1169520509355">
	    <para id="campiona_statement2D">
	    A continuous-space signal <m:math>
	      <m:apply>
		<m:ci type="fn">s</m:ci>
		<m:ci>x</m:ci>
		<m:ci>y</m:ci>
	      </m:apply>
	    </m:math>, whose spectral content is limited to spatial
	    frequencies belonging to the rectangle having semi-edges
	    <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>bX</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> and <m:math> <m:ci>
		<m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>bY</m:mn>
		</m:msub>
	      </m:ci>
	    </m:math> (i.e., bandlimited) can be recovered from its sampled version
	      <m:math>
		<m:apply> <m:ci type="fn">s</m:ci> <m:ci>m</m:ci>
		<m:ci>n</m:ci>
	      </m:apply>
	    </m:math> if the spatial sampling rates are larger than
	    twice the respective bandwidths (i.e., if <m:math>
		<m:apply>
		  <m:gt/>
		  <m:ci>
		    <m:msub>
		      <m:mi>F</m:mi>
		      <m:mn>X</m:mn>
		    </m:msub>
		  </m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		  <m:ci>
		    <m:msub>
		      <m:mi>F</m:mi>
		      <m:mn>bX</m:mn>
		    </m:msub>
		  </m:ci>
		  </m:apply>
		</m:apply>
	      </m:math> and <m:math>
		<m:apply>
		  <m:gt/>
		  <m:ci>
		    <m:msub>
		      <m:mi>F</m:mi>
		      <m:mn>Y</m:mn>
		    </m:msub>
		  </m:ci>
		  <m:apply>
		    <m:times/>
		    <m:cn>2</m:cn>
		  <m:ci>
		    <m:msub>
		      <m:mi>F</m:mi>
		      <m:mn>bY</m:mn>
		    </m:msub>
		  </m:ci>
		  </m:apply>
		</m:apply>
	      </m:math>)
	    </para>
	  </statement>
	</rule>
	<para id="camp_rico2D">
	  In practice, the spatial sampling step can not be larger
	  than the semi-period of the finest spatial frequency (or the
	  finest detail) that is represented in the image. The
	  reconstruction can only be done through a filter that
	  eliminates all the spectral images but the one coming
	  directly from the original continuous-space signal. In other
	  words, the filter will cut all images whose frequency
	  components are higher than the <term>Nyquist
	  frequency</term> defined as <m:math>
	    <m:apply>
	      <m:divide/>
	      <m:ci><m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>X</m:mn>
		</m:msub>
	      </m:ci>
	      <m:cn>2</m:cn>
	    </m:apply>
	  </m:math> and <m:math>
	    <m:apply>
	      <m:divide/>
	      <m:ci><m:msub>
		  <m:mi>F</m:mi>
		  <m:mn>Y</m:mn>
		</m:msub>
	      </m:ci>
	      <m:cn>2</m:cn>
	    </m:apply>
	  </m:math> along the two axes. The condition required by the
	  <link target-id="teorema_campionamento2D">sampling
	  theorem</link> is equivalent to requiring that there are no
	  overlaps between spectral images. If there were such
	  overlaps, it wouldn't be possible to eliminate the copies of
	  the original signal spectrum by means of filtering. In case of overlapping, a filter
	  cutting all frequency components higher than the Nyquist
	  frequency would give back a signal that is affected by
	  aliasing.
	</para>
	<para id="resampling2D">
	  We note how aliasing can be produced by down-sampling (or
	  decimating) a sampled image. Starting from a discrete-space
	  image, we can select only a subset of samples arranged in a
	  regular grid. This will determine the periodic repetition of
	  the spectral images, that will end up overlapping.
	</para>
	<para id="applet_samplingp">
	  In order to explore the concepts of sampling, down-sampling,
	  and aliasing, run the <link resource="resampling_ellipse.html">applet drawing ellipses
	  </link>. With the keyboard arrow you can double or halve the
	  horizontal and vertical sampling steps.
	</para>
      </section>

      <para id="image_proc_basics">A simple introduction to the first
elements of image processing is found in <link document="m10973">
Digital Image Processing Basics</link>. </para>
    </section>
    <section id="quantizzazione">
      <title>Quantization</title>
      <para id="quantizzazionep">
	With the adjective "digital" we indicate those systems that
	work on signals that are represented by numbers, with the
	(finite) precision that computing systems allow. Up to now we
	have considered discrete-time and discrete-space signals as if
	they were collections of infinite-precision numbers, or real
	numbers. Unfortunately, computers only allow to represent
	finite subsets of rational numbers. This means that our
	signals are subject to quantization.
      </para>
      <para id="quantlinp">
	For our purposes, the most interesting quantization is the
	  linear one, which is usually occurring in the process of
	  conversion of an analog signal into the digital domain. If
	  the memory word dedicated to storing a number is made of
	  <m:math> <m:ci>b</m:ci> </m:math> bits, then the range of
	  such number is discretized into
	  <m:math>
	  <m:apply>
	    <m:power/>
	    <m:mn>2</m:mn>
	    <m:ci>b</m:ci>
	  </m:apply>
	</m:math> quantization levels. Any value that is found between
	  two quantization levels can be approximated by truncation or
	  rounding to the closest value. The <link target-id="ottoquanti"/> shows an example of quantization with
	  representation on <m:math> <m:cn>3</m:cn> </m:math> bits in
	  <link document="m10808"> two's complement</link>.
      </para>
	<figure id="ottoquanti">
	  <title>Sampling and quantization of an analog signal</title>
	  <media id="id1169534341642" alt=""><image src="../../media/quant.png" mime-type="image/png"/></media>
	</figure>
      <para id="quanterrorp">
	The approximation introduced by quantization manifests itself
	as a noise, called <term>quantization noise</term>. Often, for
	the analysis of sound-processing circuits, such noise is
	assumed to be white and de-correlated with the signal, but in reality
	it is perceptually tied to the signal itself, in such an
	extent that quantization can be perceived as an effect.
      </para>
      <para id="applet_quant">To have a visual and intuitive exploration of the phenomenon
	of quantization, consider the <link resource="quantagondoleBeads.html">
	applet </link> that allows to vary between <m:math>
	<m:cn>1</m:cn> </m:math> and <m:math> <m:cn>8</m:cn> </m:math>
	the number of bits dedicated to the representation of each of
	the RGB channels representing color. The same number of bits
	is dedicated to the representation of an audio signal coupled
	to the image. The visual effect that is obtained by reducing
	the number of bits is similar to a <term>solarization</term>.
	</para>
    </section>
    <exercise id="estensioni_aliasing">
      <problem id="id1169527328604">
	<para id="estensionip">
	  Extend the code of the applet <link target-id="aliasingTab"/> to add some interaction features:
	  <list id="estensionil">
	    <item>Make the fundamental frequency of the
	    automatically-generated sound changing randomly at each
	    frame (see <link url="http://www.processing.org/reference/random_.html"><code>random()</code></link>).</item>

	    <item>Make the framerate (and the metronome for generating
	    notes) dependent on the horizontal position of the mouse
	    (<code>mouseX</code>). </item>

	    <item>Make the number of harmonics of the sound (i.e., its
	    brightness) dependent on the vertical position of the
	    mouse (<code>mouseY</code>).</item>

	    <item>Paint the window background in such a way that
	    moving from left to right the tint changes from blue to
	    red. In this way, a blue color will correspond to a slow
	    tempo, and a red color to a fast tempo.</item>

	    <item>Make the color saturation of the background
	    dependent on the vertical position of the mouse. In this
	    way a sound with a few harmonics (low brightness) will
	    correspond to a grayish color, while a sound rich of
	    harmonics (high brightness) will correspond to a saturated
	    color. </item>

	    <item>Add a control to stop the computation and display of
	    the spectrum and create an effect of image freezing, while
	    sound continues to be generated (for instance by keeping
	    the mouse button pressed).</item>

	    <item>Add a control to cancel the dependence of tempo,
	    brightness, and color saturation on mouse position (for
	    instance by pressing a key). </item>

	    <item>Add a control that, in case of image freezing (mouse
	    button pressed), will stop the generation of new notes
	    while "freezing" the current note. </item>
 
	    <item>Finally, add a control that, in case of image
	    freezing, will stop the sound generation and make the
	    application silent.</item>
	  </list>
	</para>
      </problem>
      <solution id="id1169520330174">
	<para id="estensionis">The proposed extensions are implemented in the  <link resource="./aliasingfermoDBeads.pde">Processing code</link>.
	</para>
      </solution>
    </exercise>
  </content>
  
<bib:file>
<bib:entry id="rocISP">
<bib:book>
<bib:author>Davide Rocchesso</bib:author> <bib:title>Introduction to
Sound Processing</bib:title> <bib:publisher>Mondo
Estremo</bib:publisher> <bib:year>2003</bib:year>
<bib:note>http://www.mondo-estremo.com</bib:note>
</bib:book>
</bib:entry>
</bib:file>

</document>